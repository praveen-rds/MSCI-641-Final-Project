{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9011341,"sourceType":"datasetVersion","datasetId":5429387}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BartForConditionalGeneration, BartTokenizer, AdamW, get_scheduler\nfrom datasets import load_metric, list_metrics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-03T18:35:29.402734Z","iopub.execute_input":"2024-08-03T18:35:29.403540Z","iopub.status.idle":"2024-08-03T18:35:39.506554Z","shell.execute_reply.started":"2024-08-03T18:35:29.403509Z","shell.execute_reply":"2024-08-03T18:35:39.505536Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/clickbait-task2/train_data.csv')\nval = pd.read_csv('/kaggle/input/clickbait-task2/val_data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:39.508614Z","iopub.execute_input":"2024-08-03T18:35:39.509411Z","iopub.status.idle":"2024-08-03T18:35:39.820966Z","shell.execute_reply.started":"2024-08-03T18:35:39.509373Z","shell.execute_reply":"2024-08-03T18:35:39.819917Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:39.822320Z","iopub.execute_input":"2024-08-03T18:35:39.822636Z","iopub.status.idle":"2024-08-03T18:35:39.851409Z","shell.execute_reply.started":"2024-08-03T18:35:39.822610Z","shell.execute_reply":"2024-08-03T18:35:39.850576Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  ['wes welker wanted dinner with tom brady but ...   \n1  ['nasa sets date for full recovery of ozone ho...   \n2  ['this is what makes employees happy  and its ...   \n3  ['passion is overrated \\xa07 work habits you n...   \n4  ['the perfect way to cook rice so that its per...   \n\n                                              output       labels  \n0             ['how about that morning we go throw']  ['passage']  \n1                                           ['2070']   ['phrase']  \n2                       ['intellectual stimulation']   ['phrase']  \n3  ['purpose connects us to something bigger and ...    ['multi']  \n4                               ['in a rice cooker']   ['phrase']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>output</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['wes welker wanted dinner with tom brady but ...</td>\n      <td>['how about that morning we go throw']</td>\n      <td>['passage']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['nasa sets date for full recovery of ozone ho...</td>\n      <td>['2070']</td>\n      <td>['phrase']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['this is what makes employees happy  and its ...</td>\n      <td>['intellectual stimulation']</td>\n      <td>['phrase']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['passion is overrated \\xa07 work habits you n...</td>\n      <td>['purpose connects us to something bigger and ...</td>\n      <td>['multi']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['the perfect way to cook rice so that its per...</td>\n      <td>['in a rice cooker']</td>\n      <td>['phrase']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:39.853775Z","iopub.execute_input":"2024-08-03T18:35:39.854202Z","iopub.status.idle":"2024-08-03T18:35:39.864007Z","shell.execute_reply.started":"2024-08-03T18:35:39.854171Z","shell.execute_reply":"2024-08-03T18:35:39.863074Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  ['five nights at freddys sequel delayed for we...   \n1  ['why arizona sheriff joe arpaios fate could h...   \n2  ['heres how much you should be tipping your ha...   \n3  ['harry potter alums reunite for new movie', '...   \n4  ['a man swallowed a microsd card and you wont ...   \n\n                                              output       labels  \n0  ['some of the plot elements are so disturbing ...  ['passage']  \n1  ['intentionally', 'could transform a court cas...    ['multi']  \n2                                             ['20']   ['phrase']  \n3             ['alan rickman  rupert grint', 'cbgb']    ['multi']  \n4  ['a man who swallowed a 64gb microsd card and ...  ['passage']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>output</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['five nights at freddys sequel delayed for we...</td>\n      <td>['some of the plot elements are so disturbing ...</td>\n      <td>['passage']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['why arizona sheriff joe arpaios fate could h...</td>\n      <td>['intentionally', 'could transform a court cas...</td>\n      <td>['multi']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['heres how much you should be tipping your ha...</td>\n      <td>['20']</td>\n      <td>['phrase']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['harry potter alums reunite for new movie', '...</td>\n      <td>['alan rickman  rupert grint', 'cbgb']</td>\n      <td>['multi']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['a man swallowed a microsd card and you wont ...</td>\n      <td>['a man who swallowed a 64gb microsd card and ...</td>\n      <td>['passage']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_inputs = train['text'].astype(str).tolist()\ntrain_outputs = train['output'].astype(str).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:39.865390Z","iopub.execute_input":"2024-08-03T18:35:39.866098Z","iopub.status.idle":"2024-08-03T18:35:39.883073Z","shell.execute_reply.started":"2024-08-03T18:35:39.866062Z","shell.execute_reply":"2024-08-03T18:35:39.882146Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"val_inputs = val['text'].astype(str).tolist()\nval_outputs = val['text'].astype(str).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:39.884518Z","iopub.execute_input":"2024-08-03T18:35:39.885199Z","iopub.status.idle":"2024-08-03T18:35:39.895218Z","shell.execute_reply.started":"2024-08-03T18:35:39.885173Z","shell.execute_reply":"2024-08-03T18:35:39.894316Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name = 'facebook/bart-large-cnn'\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:39.896259Z","iopub.execute_input":"2024-08-03T18:35:39.896806Z","iopub.status.idle":"2024-08-03T18:35:51.649832Z","shell.execute_reply.started":"2024-08-03T18:35:39.896768Z","shell.execute_reply":"2024-08-03T18:35:51.649026Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6aa25fd23704ce2a18406092231530b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba4696119fd4caca0c8d87249f0373a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"876f89a3decf431da742d1e4399d7daa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"502df2efff1d488698f2d3402d7c8264"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dd9c4b22f65480ab5a851465758a3f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19209a04b1e44ad5a106c9eeef0981da"}},"metadata":{}}]},{"cell_type":"code","source":"train_encodings = tokenizer(train_inputs, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\ntrain_labels = tokenizer(train_outputs, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n\nval_encodings = tokenizer(val_inputs, padding=True, truncation=True, max_length=512)\nval_labels = tokenizer(val_outputs, padding=True, truncation=True, max_length=256)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:35:51.651950Z","iopub.execute_input":"2024-08-03T18:35:51.652266Z","iopub.status.idle":"2024-08-03T18:36:20.734437Z","shell.execute_reply.started":"2024-08-03T18:35:51.652241Z","shell.execute_reply":"2024-08-03T18:36:20.733621Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class BartlargecnnDataset(Dataset):\n    def __init__(self,encodings,labels):\n        self.encodings = encodings\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.encodings['input_ids'])\n    \n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n        return item","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:20.735424Z","iopub.execute_input":"2024-08-03T18:36:20.735687Z","iopub.status.idle":"2024-08-03T18:36:20.741811Z","shell.execute_reply.started":"2024-08-03T18:36:20.735665Z","shell.execute_reply":"2024-08-03T18:36:20.741011Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset = BartlargecnnDataset(train_encodings, train_labels)\nval_dataset = BartlargecnnDataset(val_encodings, val_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:20.743039Z","iopub.execute_input":"2024-08-03T18:36:20.743324Z","iopub.status.idle":"2024-08-03T18:36:20.753582Z","shell.execute_reply.started":"2024-08-03T18:36:20.743301Z","shell.execute_reply":"2024-08-03T18:36:20.752712Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:20.754520Z","iopub.execute_input":"2024-08-03T18:36:20.754762Z","iopub.status.idle":"2024-08-03T18:36:20.765560Z","shell.execute_reply.started":"2024-08-03T18:36:20.754741Z","shell.execute_reply":"2024-08-03T18:36:20.764796Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"lr = 5e-5\nepochs = 10\n\noptimizer = AdamW(model.parameters(), lr = lr)\n\nnum_training_steps = epochs * len(train_loader)\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:20.768136Z","iopub.execute_input":"2024-08-03T18:36:20.768567Z","iopub.status.idle":"2024-08-03T18:36:21.909826Z","shell.execute_reply.started":"2024-08-03T18:36:20.768534Z","shell.execute_reply":"2024-08-03T18:36:21.908955Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel.to(device)\nprint('Using device:', device)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:21.910970Z","iopub.execute_input":"2024-08-03T18:36:21.911562Z","iopub.status.idle":"2024-08-03T18:36:22.575314Z","shell.execute_reply.started":"2024-08-03T18:36:21.911532Z","shell.execute_reply":"2024-08-03T18:36:22.574410Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install -U nltk","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:22.576669Z","iopub.execute_input":"2024-08-03T18:36:22.576973Z","iopub.status.idle":"2024-08-03T18:36:40.455665Z","shell.execute_reply.started":"2024-08-03T18:36:22.576947Z","shell.execute_reply":"2024-08-03T18:36:40.454585Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.meteor_score import meteor_score\nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:40.457384Z","iopub.execute_input":"2024-08-03T18:36:40.457709Z","iopub.status.idle":"2024-08-03T18:36:41.984139Z","shell.execute_reply.started":"2024-08-03T18:36:40.457679Z","shell.execute_reply":"2024-08-03T18:36:41.983206Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(epochs):\n  model.train()\n  for batch in train_loader:\n        \n    batch = {k: v.to(device) for k, v in batch.items()}\n    \n    optimizer.zero_grad()\n\n    outputs = model(**batch)\n    loss = outputs.loss\n    loss.backward()\n\n    optimizer.step()\n    lr_scheduler.step()\n\n  print(f\"Epoch: {epoch +1} / {epochs}, Loss: {loss.item()}\")\n\n  model.eval()\n  predictions = []\n  references = []\n  val_loss = 0\n\n  for batch in val_loader:\n      batch = {k: v.to(device) for k, v in batch.items()}\n      with torch.no_grad():\n          outputs = model(**batch)\n          loss = outputs.loss\n          val_loss += loss.item()\n          input_ids = batch['input_ids']\n          inputs = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n          generate_outputs = model.generate(input_ids)\n          preds = tokenizer.batch_decode(generate_outputs, skip_special_tokens=True)\n          labels = batch['labels']\n          refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n          predictions.extend(preds)\n          references.extend(refs)\n  \n  average_val_loss = val_loss / len(val_loader)\n  print(f\"Validation Loss: {average_val_loss}\")\n\n  tokenized_predictions = [word_tokenize(pred) for pred in predictions]\n  tokenized_references = [word_tokenize(ref) for ref in references]\n\n  meteor_scores = [meteor_score([ref], pred) for pred, ref in zip(tokenized_predictions, tokenized_references)]\n  average_meteor = sum(meteor_scores) / len(meteor_scores) if meteor_scores else 0\n  print(f\"METEOR Score: {average_meteor}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:36:41.985640Z","iopub.execute_input":"2024-08-03T18:36:41.986486Z","iopub.status.idle":"2024-08-03T22:29:31.130545Z","shell.execute_reply.started":"2024-08-03T18:36:41.986449Z","shell.execute_reply":"2024-08-03T22:29:31.129566Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3364922649.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_34/3364922649.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 / 10, Loss: 0.047888290137052536\nValidation Loss: 0.2975501385331154\nMETEOR Score: 0.21864447254359573\nEpoch: 2 / 10, Loss: 0.006322705186903477\nValidation Loss: 0.3339382611215115\nMETEOR Score: 0.27483293907383166\nEpoch: 3 / 10, Loss: 0.11850340664386749\nValidation Loss: 0.44221220090985297\nMETEOR Score: 0.2230323903366123\nEpoch: 4 / 10, Loss: 0.030949953943490982\nValidation Loss: 0.4217720675468445\nMETEOR Score: 0.21691047218971252\nEpoch: 5 / 10, Loss: 0.005358950700610876\nValidation Loss: 0.4937809407711029\nMETEOR Score: 0.20160970400757383\nEpoch: 6 / 10, Loss: 0.002858840860426426\nValidation Loss: 0.5765578031539917\nMETEOR Score: 0.2141425166717923\nEpoch: 7 / 10, Loss: 0.0011548403417691588\nValidation Loss: 0.5470558378100395\nMETEOR Score: 0.21700375683777778\nEpoch: 8 / 10, Loss: 0.0005930097540840507\nValidation Loss: 0.5334890785813332\nMETEOR Score: 0.21553154612047457\nEpoch: 9 / 10, Loss: 0.004765598569065332\nValidation Loss: 0.6139420327544213\nMETEOR Score: 0.21825957098270585\nEpoch: 10 / 10, Loss: 9.619428601581603e-05\nValidation Loss: 0.6519375768303871\nMETEOR Score: 0.2089563349938317\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/Bart_large_cnn_model_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:31.133566Z","iopub.execute_input":"2024-08-03T22:29:31.133865Z","iopub.status.idle":"2024-08-03T22:29:33.810588Z","shell.execute_reply.started":"2024-08-03T22:29:31.133839Z","shell.execute_reply":"2024-08-03T22:29:33.809725Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:34.374149Z","iopub.execute_input":"2024-08-03T22:29:34.374551Z","iopub.status.idle":"2024-08-03T22:29:34.588182Z","shell.execute_reply.started":"2024-08-03T22:29:34.374506Z","shell.execute_reply":"2024-08-03T22:29:34.587262Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/tokenizer_config.json',\n '/kaggle/working/special_tokens_map.json',\n '/kaggle/working/vocab.json',\n '/kaggle/working/merges.txt',\n '/kaggle/working/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"  test = pd.read_csv('/kaggle/input/clickbait-task2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:34.589425Z","iopub.execute_input":"2024-08-03T22:29:34.589749Z","iopub.status.idle":"2024-08-03T22:29:34.643557Z","shell.execute_reply.started":"2024-08-03T22:29:34.589723Z","shell.execute_reply":"2024-08-03T22:29:34.642713Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:34.644743Z","iopub.execute_input":"2024-08-03T22:29:34.645088Z","iopub.status.idle":"2024-08-03T22:29:34.655483Z","shell.execute_reply.started":"2024-08-03T22:29:34.645058Z","shell.execute_reply":"2024-08-03T22:29:34.654501Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   id                                           features\n0   0  ['he tackles a nurse at the hospital then you ...\n1   1  ['why you should be selfish at work', 'were al...\n2   2  ['the one strange trick that will make you liv...\n3   3  ['nerd wins scrabble championship with word yo...\n4   4  ['the bizarre new way to eat eggs that has eve...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>['he tackles a nurse at the hospital then you ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>['why you should be selfish at work', 'were al...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>['the one strange trick that will make you liv...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>['nerd wins scrabble championship with word yo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>['the bizarre new way to eat eggs that has eve...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_inputs = test['features'].astype(str).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:34.656812Z","iopub.execute_input":"2024-08-03T22:29:34.657162Z","iopub.status.idle":"2024-08-03T22:29:34.665881Z","shell.execute_reply.started":"2024-08-03T22:29:34.657135Z","shell.execute_reply":"2024-08-03T22:29:34.665160Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_encodings = tokenizer(test_inputs, truncation=True, padding=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:34.667256Z","iopub.execute_input":"2024-08-03T22:29:34.667669Z","iopub.status.idle":"2024-08-03T22:29:37.211214Z","shell.execute_reply.started":"2024-08-03T22:29:34.667638Z","shell.execute_reply":"2024-08-03T22:29:37.210375Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n  def __init__(self, encodings):\n        self.encodings = encodings\n\n  def __len__(self):\n        return len(self.encodings['input_ids'])\n\n  def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:37.212410Z","iopub.execute_input":"2024-08-03T22:29:37.212706Z","iopub.status.idle":"2024-08-03T22:29:37.218684Z","shell.execute_reply.started":"2024-08-03T22:29:37.212681Z","shell.execute_reply":"2024-08-03T22:29:37.217759Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_data = TestDataset(test_encodings)\ntest_loader = DataLoader(test_data, batch_size= 4 , shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:37.219854Z","iopub.execute_input":"2024-08-03T22:29:37.220155Z","iopub.status.idle":"2024-08-03T22:29:37.254571Z","shell.execute_reply.started":"2024-08-03T22:29:37.220131Z","shell.execute_reply":"2024-08-03T22:29:37.253887Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.eval()\npredictions = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        input_ids = batch['input_ids']\n        outputs = model.generate(input_ids)\n        preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        predictions.extend(preds)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:29:37.255595Z","iopub.execute_input":"2024-08-03T22:29:37.255857Z","iopub.status.idle":"2024-08-03T22:34:27.503257Z","shell.execute_reply.started":"2024-08-03T22:29:37.255834Z","shell.execute_reply":"2024-08-03T22:34:27.502433Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame(columns = ['id', 'spoiler'])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:34:27.507513Z","iopub.execute_input":"2024-08-03T22:34:27.507858Z","iopub.status.idle":"2024-08-03T22:34:27.514247Z","shell.execute_reply.started":"2024-08-03T22:34:27.507830Z","shell.execute_reply":"2024-08-03T22:34:27.513300Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"pred_df['id'] = test['id']\npred_df['spoiler'] = predictions","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:34:27.515537Z","iopub.execute_input":"2024-08-03T22:34:27.515837Z","iopub.status.idle":"2024-08-03T22:34:27.550610Z","shell.execute_reply.started":"2024-08-03T22:34:27.515813Z","shell.execute_reply":"2024-08-03T22:34:27.549693Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:34:27.551935Z","iopub.execute_input":"2024-08-03T22:34:27.552318Z","iopub.status.idle":"2024-08-03T22:34:27.568492Z","shell.execute_reply.started":"2024-08-03T22:34:27.552280Z","shell.execute_reply":"2024-08-03T22:34:27.567491Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   id                                            spoiler\n0   0  ['gave him an experimental kidney transplant a...\n1   1  ['giving at the expense of your own wellbeing ...\n2   2  ['meditating inside a beautiful stockphoto roo...\n3   3  ['braconid', 'any of numerous wasps of the fam...\n4   4  ['cured egg yolks are deliciousbut strong beca...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>spoiler</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>['gave him an experimental kidney transplant a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>['giving at the expense of your own wellbeing ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>['meditating inside a beautiful stockphoto roo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>['braconid', 'any of numerous wasps of the fam...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>['cured egg yolks are deliciousbut strong beca...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pred_df['spoiler'] = pred_df['spoiler'].apply(lambda x: ', '.join(x.strip(\"[]'\").split(\"', '\")))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:34:27.569923Z","iopub.execute_input":"2024-08-03T22:34:27.570453Z","iopub.status.idle":"2024-08-03T22:34:27.580832Z","shell.execute_reply.started":"2024-08-03T22:34:27.570422Z","shell.execute_reply":"2024-08-03T22:34:27.579751Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"pred_df.to_csv('/kaggle/working/output_BART_lr5e-5_large_cnn_file.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:34:27.581892Z","iopub.execute_input":"2024-08-03T22:34:27.582173Z","iopub.status.idle":"2024-08-03T22:34:27.606797Z","shell.execute_reply.started":"2024-08-03T22:34:27.582150Z","shell.execute_reply":"2024-08-03T22:34:27.606057Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accumulation_steps = 4 \ntotal_loss = 0.0\n\nfor epoch in range(epochs):\n  model.train()\n  total_loss = 0.0 \n    \n  for step, batch in enumerate(train_loader):\n        \n    batch = {k: v.to(device) for k, v in batch.items()}\n    if (step + 1) % accumulation_steps == 0:\n        optimizer.zero_grad()\n\n    outputs = model(**batch)\n    loss = outputs.loss /accumulation_steps\n    loss.backward()\n    total_loss += loss.item()\n    \n    if (step + 1) % accumulation_steps == 0:\n        optimizer.step()\n        lr_scheduler.step()\n        \n  avg_loss = total_loss / len(train_loader) \n  print(f\"Epoch: {epoch +1} / {num_epochs}, Training_Loss: {avg_loss}\")\n\n  model.eval()\n  predictions = []\n  references = []\n  val_loss = 0.0\n\n  for batch in val_loader:\n      batch = {k: v.to(device) for k, v in batch.items()}\n      outputs = model(**batch)\n      loss = outputs.loss\n      val_loss += loss.item()\n      input_ids = batch['input_ids']\n      inputs = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n      generate_outputs = model.generate(input_ids)\n      preds = tokenizer.batch_decode(generate_outputs, skip_special_tokens=True)\n      labels = batch['labels']\n      refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n      predictions.extend(preds)\n      references.extend(refs)\n    \n  average_val_loss = val_loss / len(val_loader)\n  print(f\"Validation Loss: {average_val_loss}\")\n        \n  tokenized_predictions = [word_tokenize(pred) for pred in predictions]\n  tokenized_references = [word_tokenize(ref) for ref in references]\n\n  meteor_scores = [meteor_score([ref], pred) for pred, ref in zip(tokenized_predictions, tokenized_references)]\n  average_meteor = sum(meteor_scores) / len(meteor_scores) if meteor_scores else 0\n  print(f\"METEOR Score: {average_meteor}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}