{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9012858,"sourceType":"datasetVersion","datasetId":5430468},{"sourceId":9082595,"sourceType":"datasetVersion","datasetId":5479889},{"sourceId":9096850,"sourceType":"datasetVersion","datasetId":5490001},{"sourceId":189393140,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report, f1_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom transformers import BertTokenizer\nfrom datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom transformers import BartTokenizer, BartForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BartForSequenceClassification, BartTokenizer, AdamW, get_scheduler\nfrom datasets import load_metric, list_metrics\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:11:54.869137Z","iopub.execute_input":"2024-08-03T15:11:54.869407Z","iopub.status.idle":"2024-08-03T15:12:16.505038Z","shell.execute_reply.started":"2024-08-03T15:11:54.869383Z","shell.execute_reply":"2024-08-03T15:12:16.504017Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-03 15:12:05.727830: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-03 15:12:05.727968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-03 15:12:05.886578: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load your data\ntrain = pd.read_csv('/kaggle/input/datasetscsv/train_data.csv')\nval = pd.read_csv('/kaggle/input/datasetscsv/val_data.csv')\ntest = pd.read_csv('/kaggle/input/datasetscsv/test.csv')\n\n# Ensure the columns are named correctly\ntrain_inputs = train['text'].astype(str).tolist()\ntrain_labels = train['labels'].astype(str).tolist()\n\nval_inputs = val['text'].astype(str).tolist()\nval_labels = val['labels'].astype(str).tolist()\n\ntest_inputs = test['text'].astype(str).tolist()\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform([label.strip(\"[]'\") for label in train_labels])\nval_labels = label_encoder.transform([label.strip(\"[]'\") for label in val_labels])\n\n# Save label mapping for later use\nlabel_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\nprint(\"Label Mapping:\", label_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:12:24.000344Z","iopub.execute_input":"2024-08-03T15:12:24.000695Z","iopub.status.idle":"2024-08-03T15:12:24.304051Z","shell.execute_reply.started":"2024-08-03T15:12:24.000668Z","shell.execute_reply":"2024-08-03T15:12:24.302919Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Label Mapping: {'multi': 0, 'passage': 1, 'phrase': 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = 'facebook/bart-base'\ntokenizer = BartTokenizer.from_pretrained(model_name)\n\ntrain_encodings = tokenizer(train_inputs, truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_inputs, truncation=True, padding=True, max_length=512)\ntest_encodings = tokenizer(test_inputs, truncation=True, padding=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:12:25.828663Z","iopub.execute_input":"2024-08-03T15:12:25.829032Z","iopub.status.idle":"2024-08-03T15:12:52.489889Z","shell.execute_reply.started":"2024-08-03T15:12:25.829003Z","shell.execute_reply":"2024-08-03T15:12:52.488898Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94ca67cac9a4ef28649e7b6a9526045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"703316c63be94251b52b6c155a8aadc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd4c61a07bee414da3d0338600182ecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0388d576c30947a2b7748da4124dc583"}},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\ntrain_dataset = CustomDataset(train_encodings, train_labels)\nval_dataset = CustomDataset(val_encodings, val_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:12:55.623978Z","iopub.execute_input":"2024-08-03T15:12:55.624709Z","iopub.status.idle":"2024-08-03T15:12:55.631440Z","shell.execute_reply.started":"2024-08-03T15:12:55.624678Z","shell.execute_reply":"2024-08-03T15:12:55.630276Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:13:02.179074Z","iopub.execute_input":"2024-08-03T15:13:02.179872Z","iopub.status.idle":"2024-08-03T15:13:02.184680Z","shell.execute_reply.started":"2024-08-03T15:13:02.179817Z","shell.execute_reply":"2024-08-03T15:13:02.183467Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = BartForSequenceClassification.from_pretrained(model_name, num_labels=len(set(train_labels)))\n\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\nnum_epochs = 10\nnum_training_steps = num_epochs * len(train_loader)\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:13:04.802354Z","iopub.execute_input":"2024-08-03T15:13:04.802966Z","iopub.status.idle":"2024-08-03T15:13:10.099620Z","shell.execute_reply.started":"2024-08-03T15:13:04.802937Z","shell.execute_reply":"2024-08-03T15:13:10.098722Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a99888c91284c14a25873cb8e39e8b1"}},"metadata":{}},{"name":"stderr","text":"Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"BartForSequenceClassification(\n  (model): BartModel(\n    (shared): Embedding(50265, 768, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (classification_head): BartClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.0, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:13:15.416201Z","iopub.execute_input":"2024-08-03T15:13:15.417256Z","iopub.status.idle":"2024-08-03T15:13:15.422665Z","shell.execute_reply.started":"2024-08-03T15:13:15.417222Z","shell.execute_reply":"2024-08-03T15:13:15.421353Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    for batch in train_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        \n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n\n    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:13:30.319895Z","iopub.execute_input":"2024-08-03T15:13:30.320521Z","iopub.status.idle":"2024-08-03T16:17:25.110401Z","shell.execute_reply.started":"2024-08-03T15:13:30.320488Z","shell.execute_reply":"2024-08-03T16:17:25.109420Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch: 1/10, Loss: 1.1224925518035889\nEpoch: 2/10, Loss: 1.032193660736084\nEpoch: 3/10, Loss: 0.9308426380157471\nEpoch: 4/10, Loss: 1.1798183917999268\nEpoch: 5/10, Loss: 0.014200051315128803\nEpoch: 6/10, Loss: 0.029484545812010765\nEpoch: 7/10, Loss: 0.026720760390162468\nEpoch: 8/10, Loss: 0.04601813107728958\nEpoch: 9/10, Loss: 0.0004217004752717912\nEpoch: 10/10, Loss: 0.001737871440127492\n","output_type":"stream"}]},{"cell_type":"code","source":"# Switch to evaluation mode\nmodel.eval()\n\n# Prepare to collect predictions and references\npredictions = []\nreferences = []\n\n# Create DataLoader for the validation set\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n\n# Perform evaluation\nwith torch.no_grad():\n    for batch in val_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        preds = torch.argmax(outputs.logits, dim=-1)\n        predictions.extend(preds.cpu().numpy())\n        references.extend(batch['labels'].cpu().numpy())\n\n# Decode integer labels back to original label strings\ndecoded_predictions = label_encoder.inverse_transform(predictions)\ndecoded_references = label_encoder.inverse_transform(references)\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(references, predictions)\nf1 = f1_score(references, predictions, average='weighted')\nreport = classification_report(references, predictions, target_names=label_encoder.classes_)\n\nprint(f\"Validation Accuracy: {accuracy}\")\nprint(f\"Validation F1 Score: {f1}\")\nprint(\"Classification Report:\")\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:25:58.133545Z","iopub.execute_input":"2024-08-03T16:25:58.134622Z","iopub.status.idle":"2024-08-03T16:26:14.227809Z","shell.execute_reply.started":"2024-08-03T16:25:58.134574Z","shell.execute_reply":"2024-08-03T16:26:14.226796Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.665\nValidation F1 Score: 0.6635237880292499\nClassification Report:\n              precision    recall  f1-score   support\n\n       multi       0.68      0.55      0.61        84\n     passage       0.66      0.70      0.68       154\n      phrase       0.67      0.69      0.68       162\n\n    accuracy                           0.67       400\n   macro avg       0.67      0.65      0.65       400\nweighted avg       0.67      0.67      0.66       400\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the trained model and tokenizer\nmodel.save_pretrained(\"/kaggle/working/bart_clickbait_model\")\ntokenizer.save_pretrained(\"/kaggle/working/bart_clickbait_tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:26:25.426314Z","iopub.execute_input":"2024-08-03T16:26:25.426998Z","iopub.status.idle":"2024-08-03T16:26:26.864521Z","shell.execute_reply.started":"2024-08-03T16:26:25.426965Z","shell.execute_reply":"2024-08-03T16:26:26.863608Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/bart_clickbait_tokenizer/tokenizer_config.json',\n '/kaggle/working/bart_clickbait_tokenizer/special_tokens_map.json',\n '/kaggle/working/bart_clickbait_tokenizer/vocab.json',\n '/kaggle/working/bart_clickbait_tokenizer/merges.txt',\n '/kaggle/working/bart_clickbait_tokenizer/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"# Load test data\n#test = pd.read_csv('/kaggle/working/test.csv')\ntest_inputs = test['text'].astype(str).tolist()\n\n# Tokenize test data\ntest_encodings = tokenizer(test_inputs, truncation=True, padding=True, max_length=512)\n\n# Define TestDataset class\nclass TestDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item\n\n# Create DataLoader for test data\ntest_dataset = TestDataset(test_encodings)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n\n# Switch to evaluation mode\nmodel.eval()\n\n# Prepare to collect predictions\npredictions = []\n\n# Perform prediction\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        preds = torch.argmax(outputs.logits, dim=-1)\n        predictions.extend(preds.cpu().numpy())\n\n# Decode integer labels back to original label strings\ndecoded_predictions = label_encoder.inverse_transform(predictions)\n\n# Prepare the output DataFrame\npred_df = pd.DataFrame({\n    'id': test['id'],  # Adjust based on your actual test data format\n    'spoilerType': decoded_predictions\n})\n\n# Save predictions to CSV\npred_df.to_csv('/kaggle/working/output_predictions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T16:27:32.660457Z","iopub.execute_input":"2024-08-03T16:27:32.660813Z","iopub.status.idle":"2024-08-03T16:27:49.755386Z","shell.execute_reply.started":"2024-08-03T16:27:32.660784Z","shell.execute_reply":"2024-08-03T16:27:49.754588Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}